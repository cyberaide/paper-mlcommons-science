\section*{Acknowledgements}
\begin{small}
We would like to thank Samuel Jackson from the Scientific Machine Learning Group at the Rutherford Appleton Laboratory (RAL) of the Science and Technology Facilities Council (STFC)(UK) for his contributions towards the Cloud Masking benchmark. This work was supported by Wave 1 of the UKRI Strategic Priorities Fund under the EPSRC grant EP/T001569/1, particularly the ‘AI for Science’ theme within that grant, by the Alan Turing Institute and by the Benchmarking for AI for Science at Exascale (BASE) project under the EPSRC grant EP/V001310/1, along with the Facilities Funding from Science and Technology Facilities Council (STFC) of UKRI, NSF Grants 2204115 and 2204115, and DOE Award DE-SC0021418. This manuscript has been authored in part by UT-Battelle, LLC, under contract DE-AC05-00OR22725 with the US Department of Energy (DOE). The publisher acknowledges the US government license to provide public access under the \href{http://energy.gov/downloads/doe-public-access-plan}{DOE Public Access Plan} (\url{http://energy.gov/downloads/doe-public-access-plan}). This research also used resources from the Oak Ridge and Argonne Leadership Computing Facilities, which are DOE Office of Science user facilities, supported under contracts DE-AC05-00OR22725 and DE-AC02-06CH11357 respectively, and from the PEARL AI resource at the RAL, STFC. This work would not have been  possible without the continued support of MLCommons and MLCommons Research, and in particular,  we thank Peter Mattson, David Kanter and Vijay Janapa Reddi for their leadership and help.
\end{small}


